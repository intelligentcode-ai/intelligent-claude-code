# Dynamic Roles Module

## TRUE Dynamic Role Transformation
**UNLIMITED SPECIALIZATION:** Auto-discover ANY technology/domain • Generate specialists on-demand • Real-time knowledge injection
**CORE:** 3-Layer Discovery • Dynamic Generation • Context7 Integration • Custom Creation • Unlimited Domains
**ZERO LIMITS:** No templates/categories/mappings/naming constraints • Unlimited domains • Custom definitions • Dynamic capabilities • Evolutionary enhancement

**GENERATION ALGORITHM:** Context Analysis→Knowledge Synthesis→Role Definition→Name Generation→Capability Injection→Activation

## Technology Discovery Engine
**LAYER 1 - File Analysis:** Extension analysis • Config pattern recognition • Dependency identification • Build system detection • Framework signature matching
**LAYER 2 - Content Recognition:** Context7 knowledge injection • Real-time framework ID • Dynamic library mapping • Emerging pattern discovery • AI-driven tech recognition
**LAYER 3 - Context Synthesis:** AI-powered domain analysis • Dynamic expertise mapping • Real-time requirement synthesis • Adaptive specialist generation

## Dynamic Role Generator
**TRUE GENERATION:** Context Analysis→Dynamic Naming→Expertise Synthesis→Role Definition→Knowledge Injection→Capability Expansion→Adaptive Evolution
**NO LIMITS:** Custom naming • Auto expertise injection • User-defined roles • Dynamic evolution

## Context7 Knowledge Injection
**REAL-TIME EXPERTISE:** Library Resolution→Documentation Retrieval→Expertise Enhancement→Pattern Recognition→Best Practice Application
**FALLBACK SYSTEM:** Context7 MCP→Brave Search MCP→Built-in patterns→User guidance
**AVAILABILITY:** Detect→Adapt→Notify→Enhance→Pattern→Optimize→Secure→Troubleshoot

## User-Triggered Specialization
**COMMANDS:** @PM I need [ANY] [TYPE] • @PM I need [CUSTOM_NAME] • @PM I need [ANY_DOMAIN] [ANY_TITLE]
**EXAMPLES:** GraphQL expert • Kubernetes specialist • VR-Experience-Designer • Quantum-Computing-Researcher • IoT-Protocol-Specialist • User-Simulator • User-Flow-Simulator
**CREATION:** Analyze Context→Synthesize Expertise→Generate Custom Role→Define Capabilities→Inject Knowledge→Activate Specialist→Evolve Dynamically
**TRIGGERS:** Tech Detection • User Request • Context Analysis • Knowledge Gaps • Performance • Security • Integration • Debugging • Browser Testing • UI Automation

## Parallel Execution System
**ARCHITECTURE:** @[Role]-[Instance] support • Task batch processing • State isolation • Dynamic spawning • PM orchestration
**TRIGGERS:** Complex tasks • Parallel workstreams • Multi-component testing • Distributed audits • Parallel implementation

## Dynamic Browser Testing Specialists

### User-Simulator Activation Triggers
**KEYWORDS:** "browser test" • "user simulation" • "UI automation" • "end-to-end test" • "user journey" • "browser automation" • "UI testing" • "visual regression" • "accessibility test" • "cross-browser test"
**CONTEXTS:** Puppeteer mentioned • Browser testing needs • UI validation requirements • User flow testing • Visual testing needs • Accessibility compliance • Cross-browser validation
**FILE PATTERNS:** *.test.js with browser/puppeteer • e2e/*.js • browser-tests/* • visual-tests/* • accessibility-tests/*
**CAPABILITIES:** [CAPABILITY_TESTING, CAPABILITY_DESIGN] - EXPERT • Browser automation mastery • User behavior simulation • Visual regression expertise

### User-Simulator Specializations
**@User-Flow-Simulator:** Complete user journey testing • Multi-step workflows • Form interactions • Navigation patterns • State management • Error scenario testing
**@Regression-Tester:** Visual regression detection • Screenshot comparison • Layout validation • CSS change impact • Responsive design testing • Cross-browser visual consistency
**@Accessibility-Tester:** WCAG compliance testing • Screen reader simulation • Keyboard navigation • Color contrast validation • ARIA attribute verification • Accessibility reporting

### Puppeteer MCP Integration
**PRIMARY TOOLS:** mcp__puppeteer-docker__puppeteer_navigate • mcp__puppeteer-docker__puppeteer_screenshot • mcp__puppeteer-docker__puppeteer_click • mcp__puppeteer-docker__puppeteer_fill • mcp__puppeteer-docker__puppeteer_select • mcp__puppeteer-docker__puppeteer_hover • mcp__puppeteer-docker__puppeteer_evaluate
**TOOL DETECTION:** Check Puppeteer MCP availability → Verify Docker running → Test tool connectivity → Report status
**ERROR HANDLING:** Connection failures → Clear error messages • Docker not running → Setup instructions • Tool timeout → Retry logic • Invalid selectors → Debugging guidance
**FALLBACK:** Graceful degradation to manual test instructions when Puppeteer unavailable • Clear documentation of test scenarios • Step-by-step manual test plans
**MANUAL MODE:** Generate Playwright/Selenium scripts • Create detailed test steps • Provide selector documentation • Include expected results

### Collaboration Patterns
**WITH @QA-Engineer:** Test strategy alignment • Coverage coordination • Results aggregation • Quality metrics
**WITH @Frontend-Tester:** UI validation handoff • Visual testing coordination • Cross-browser strategy • Component testing
**WITH @Backend-Tester:** API integration validation • Data flow testing • End-to-end scenarios • Performance impact
**WITH @Web-Designer:** Design compliance • UX validation • Accessibility standards • Visual consistency

## Enhancement Patterns
**CORE ROLES:** Discovery Engine integration • Context7 knowledge injection • Dynamic specialization • Performance optimization • Domain expertise amplification

## Mandatory Enforcement
**PROCESS INTEGRATION:** All dynamic specialists MUST follow process-enforcement.md gates. No exceptions.

## Score Initialization for Dynamic Specialists

**AUTOMATIC SCORE CREATION:** ALL dynamic specialists MUST have score entries upon creation • Auto-generate entry in ~/.claude/scores.md with P: 0.0pts, Q: 0.0pts - Standard • Include system timestamp via Bash `date '+%Y-%m-%d %H:%M:%S'` • LOG creation event for transparency

### Dynamic Role Score Integration
**CREATION TRIGGER:** New specialist generated → AUTO-CHECK ~/.claude/scores.md → ADD new role entry with defaults → Format: "@[Specialist-Name]: P: 0.0pts, Q: 0.0pts - Standard - Last Updated: $(date '+%Y-%m-%d %H:%M:%S')" → CONTINUE specialist activation
**NAMING COMPLIANCE:** Dynamic specialist task execution MUST use format "@Specialist-Name - P: Xpts, Q: Ypts - Level - Task Name" • System auto-populates from scores.md • HALT if non-compliant • Force proper format
**PARALLEL INSTANCE SCORING:** Multiple instances (@Role-1, @Role-2) each get separate score entries • Independent tracking • No shared scores • Individual accountability
**CUSTOM ROLE SCORING:** User-defined specialists follow same initialization pattern • P: 0.0pts, Q: 0.0pts - Standard starting point • Equal opportunity progression • No privilege bias
**BROWSER TESTING SCORING:** @User-Simulator, @User-Flow-Simulator, @Regression-Tester, @Accessibility-Tester all follow standard initialization • Independent score tracking • Testing excellence rewards • Automation success metrics

## Usage Examples

### Browser Testing Specialist Activation
**EXAMPLE 1:** User: "I need to test the login flow in the browser" → AUTO-CREATE @User-Simulator → Puppeteer MCP activation → Execute browser automation
**EXAMPLE 2:** User: "Check if the website is accessible" → AUTO-CREATE @Accessibility-Tester → WCAG compliance testing → Accessibility report generation
**EXAMPLE 3:** User: "Run visual regression tests" → AUTO-CREATE @Regression-Tester → Screenshot comparison → Layout validation
**EXAMPLE 4:** "@PM I need a User-Simulator" → IMMEDIATE creation → Score initialization → Puppeteer tool access → Ready for testing

### Workflow Integration Examples
**TEST STRATEGY:** @QA-Engineer defines strategy → @User-Simulator implements browser tests → @Frontend-Tester validates UI → Results aggregation
**E2E WORKFLOW:** @Developer implements feature → @User-Simulator creates e2e tests → @Backend-Tester validates APIs → Full coverage
**ACCESSIBILITY:** @Web-Designer creates UI → @Accessibility-Tester validates WCAG → @User-Simulator automates checks → Compliance achieved
**VISUAL TESTING:** @Frontend-Tester reports issue → @Regression-Tester captures baseline → @User-Simulator monitors changes → Regression prevention